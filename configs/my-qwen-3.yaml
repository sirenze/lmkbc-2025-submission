model: "my_qwen_3"

# LLM
llm_path: "Qwen/Qwen3-8B"

# Prompt templates
prompt_templates_file: "prompt_templates/my_prompts.csv"

# LLM parameters
max_new_tokens: 8192
temperature: 0.6
top_k: 20
top_p: 0.95
min_p: 0

# Quantization: useful for large models and limited computing resources
use_quantization: true

# In-context learning parameters
few_shot: 5

# Data
train_data_file: "data/train.jsonl"
